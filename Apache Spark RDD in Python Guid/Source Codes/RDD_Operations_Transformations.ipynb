{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RDD_Operations_Transformations.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNeFofwSSMb25u4kJwBU7lL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EtU-hB2ve13p"},"source":["Installing pyspark "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XM5CmkpkOgkK","executionInfo":{"status":"ok","timestamp":1619968202213,"user_tz":-330,"elapsed":41436,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"9a9845a0-5d56-46c9-e5a8-799848f69d3c"},"source":["!pip install pyspark"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n","\u001b[K     |████████████████████████████████| 212.3MB 69kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 38.6MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=3949d0f27d4e15a7733eda2e132cd66c733fc089eb3d926165b390b6827b4794\n","  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jHMHAdq1es_A"},"source":["intializing Spark Session"]},{"cell_type":"code","metadata":{"id":"CBNvVZ-yPdY9","executionInfo":{"status":"ok","timestamp":1619968242760,"user_tz":-330,"elapsed":8866,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}}},"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName('RDD_Transformations').getOrCreate()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pvjn3lBXfSIB"},"source":["Mounting Google Drive\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kxSK9diTHQy","executionInfo":{"status":"ok","timestamp":1619968285567,"user_tz":-330,"elapsed":24972,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"d5901e8e-5b13-42df-c6d6-4e40cebcd004"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HxVjNv3JfYAd"},"source":["Referencing a dataset in an external storage system in Google Drive to create RDD"]},{"cell_type":"code","metadata":{"id":"PlF3xhEFVt2u","executionInfo":{"status":"ok","timestamp":1619968829731,"user_tz":-330,"elapsed":1144,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}}},"source":["distFile = spark.sparkContext.textFile(\"/content/gdrive/My Drive/Colab Notebooks/data/dataset.txt\")"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uh9TDm2crMIO"},"source":["RDD Creation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b0TgaF9rjUg","executionInfo":{"status":"ok","timestamp":1619968371699,"user_tz":-330,"elapsed":3427,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"f308093b-2a38-432a-fd53-f064a9af1054"},"source":["data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n","rdd = spark.sparkContext.parallelize(data,5)\n","rdd_collect = rdd.collect()\n","print(\"Number of Partitions: \"+str(rdd.getNumPartitions()))\n","print(\"Action: First element: \"+str(rdd.first()))\n","print(rdd_collect)\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Number of Partitions: 5\n","Action: First element: 1\n","[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IBNCbEC0flUg"},"source":["Action to read Data in RDD"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4X3lVYIWPcQ","executionInfo":{"status":"ok","timestamp":1619968859831,"user_tz":-330,"elapsed":1683,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"de1fcfaa-6043-4486-cc58-2c43819bd7a7"},"source":["for element in distFile.collect():\n","    print(element)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["10\t5\t8\t9\t8\n","1\t17\t3\t6\t7\n","23\t19\t5\t2\t15\n","4\t20\t9\t2\t12\n","18\t8\t22\t5\t7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0CXNh2P6fu3h"},"source":["**flatMap(func)** is used When we want to output multiple elements from each input element we should use flatMap(func). \n","According to the given dataset you have to output all numbers of each line by splitting from tab spaces and you can use the below code line to do it.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIwU9arJWxs_","executionInfo":{"status":"ok","timestamp":1619968965828,"user_tz":-330,"elapsed":825,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"f55c8cde-5293-45fe-ca38-3636e5f13637"},"source":["numbers = distFile.flatMap(lambda line: line.split(\"\\t\")) \n","print(numbers.collect())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['10', '5', '8', '9', '8', '1', '17', '3', '6', '7', '23', '19', '5', '2', '15', '4', '20', '9', '2', '12', '18', '8', '22', '5', '7']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MzZYwrURf3iL"},"source":["**map(func)** is used to return a new dataset formed by passing each element of the given dataset through a function.\n","Because the returned dataset is including string typed numbers you have to convert each element to integer. Therefore, using map(func) you should pass each element to int() function.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rUguRUg-awz0","executionInfo":{"status":"ok","timestamp":1619969063674,"user_tz":-330,"elapsed":824,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"86a90ca1-af35-4d96-b1dd-529346e23429"},"source":["validNumbers = numbers.map(lambda number: int(number))\n","print(validNumbers.collect())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[10, 5, 8, 9, 8, 1, 17, 3, 6, 7, 23, 19, 5, 2, 15, 4, 20, 9, 2, 12, 18, 8, 22, 5, 7]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ryt2H-J8gHNo"},"source":["**filter(func)** is used to return a new dataset which is a subset of the given dataset. As mentioned above, you have to filter all numbers which are greater than 10. Therefore, you can use the below code line to do it.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NxBHNdanbLnK","executionInfo":{"status":"ok","timestamp":1619969136518,"user_tz":-330,"elapsed":1668,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"2636779b-bd30-4a45-e3a5-c5b05e6257e3"},"source":["filterNumber = validNumbers.filter(lambda number: number > 10) \n","print(filterNumber.collect())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[17, 23, 19, 15, 20, 12, 18, 22]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9D0AZL1RgNm3"},"source":["**operations between two datasets**"]},{"cell_type":"markdown","metadata":{"id":"odeGf9EjgiuP"},"source":["Load dataset2 as RDD and apply flatMap tranformation"]},{"cell_type":"code","metadata":{"id":"VyqUsvfMbcct","executionInfo":{"status":"ok","timestamp":1619969223765,"user_tz":-330,"elapsed":971,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}}},"source":["distFile2 = spark.sparkContext.textFile(\"/content/gdrive/My Drive/Colab Notebooks/data/dataset2.txt\")\n","numbers2 = distFile2.flatMap(lambda line: line.split(\"\\t\"))"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmU0dCz0g2Sn"},"source":["intersection(dataset2) function returns a new dataset which includes common elements of two datasets.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPIJH5V-cNdl","executionInfo":{"status":"ok","timestamp":1619969305532,"user_tz":-330,"elapsed":2573,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"c379d14d-282e-4110-8ebd-1dea63351966"},"source":["intersections = numbers.intersection(numbers2)\n","print(intersections.collect())"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['10', '20', '15', '5']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eZLIZUI-g8RC"},"source":["To return a new dataset which includes all elements of given two elements, union(dataset2) function can be used."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uB2rQhWPcakX","executionInfo":{"status":"ok","timestamp":1619969358622,"user_tz":-330,"elapsed":1066,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"70a9dc70-3479-4dcc-8556-7a0aa4e521a5"},"source":["unions = numbers.union(numbers2)\n","print(unions.collect())"],"execution_count":12,"outputs":[{"output_type":"stream","text":["['10', '5', '8', '9', '8', '1', '17', '3', '6', '7', '23', '19', '5', '2', '15', '4', '20', '9', '2', '12', '18', '8', '22', '5', '7', '10', '20', '30', '5', '10', '15', '15', '30', '45']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h6OPa9SJhAqt"},"source":["distinct() function is used to return a new dataset which contains distinct elements from a given dataset.\n","Let us take a new distinct dataset from the previously created ‘unions’ dataset.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IL3srDOScgp1","executionInfo":{"status":"ok","timestamp":1619969413102,"user_tz":-330,"elapsed":1500,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"b006fc5a-cfaf-4e8a-ddce-ad838f8ceedc"},"source":["distincts = unions.distinct() \n","print(distincts.collect())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['10', '4', '20', '12', '3', '6', '7', '23', '15', '18', '30', '8', '9', '1', '17', '19', '22', '45', '5', '2']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zEyukrjhhW8K"},"source":["**PairRDDFunctions** "]},{"cell_type":"markdown","metadata":{"id":"rHO-3iRHhHCZ"},"source":["Even though Spark operations work on RDDs containing any type of objects, there are few transformation operations in Spark RDD which consider key-value pairs.To do those types of operations let us create a new dataset which contains (K,V) pairs from dataset.txt. We take each element dataset.txt as keys and assign 1 as value for each key.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97UfNi_sdF3P","executionInfo":{"status":"ok","timestamp":1619969515765,"user_tz":-330,"elapsed":1068,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"420c9c29-94f3-48d4-dfa1-642e770d57c5"},"source":["pairs = validNumbers.map(lambda s: (s, 1))\n","print(pairs.collect())"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[(10, 1), (5, 1), (8, 1), (9, 1), (8, 1), (1, 1), (17, 1), (3, 1), (6, 1), (7, 1), (23, 1), (19, 1), (5, 1), (2, 1), (15, 1), (4, 1), (20, 1), (9, 1), (2, 1), (12, 1), (18, 1), (8, 1), (22, 1), (5, 1), (7, 1)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3fByhJFfhexK"},"source":["**groupByKey**() is used to return a dataset of (K,iterable<V>) pairs from a dataset of (K,V) pairs.Using the below code line you can return a new dataset of (K,iterable<V>) pairs grouping by keys. mapValues(list) is used to convert  iterable<V> as a list to visible elements of iterable<V>. \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtitTiHgd3KD","executionInfo":{"status":"ok","timestamp":1619969618624,"user_tz":-330,"elapsed":1022,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"7a62eb8b-ba0e-4b71-908e-c808c6ce08f9"},"source":["groups = pairs.groupByKey().mapValues(list)\n","print(groups.collect())"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[(10, [1]), (8, [1, 1, 1]), (6, [1]), (2, [1, 1]), (4, [1]), (20, [1]), (12, [1]), (18, [1]), (22, [1]), (5, [1, 1, 1]), (9, [1, 1]), (1, [1]), (17, [1]), (3, [1]), (7, [1, 1]), (23, [1]), (19, [1]), (15, [1])]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ldq9qIXDhpRH"},"source":["**ReduceByKey**(func) returns a dataset of (K,U) pairs from a dataset of (K,V) pairs. In this U is the aggregation of Vs which are related to the same keys."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8ZCqyzgd-Zd","executionInfo":{"status":"ok","timestamp":1619969683959,"user_tz":-330,"elapsed":1503,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"43514266-b42b-465c-faf8-aaa57d43bbf5"},"source":["counts = pairs.reduceByKey(lambda a, b: a + b)\n","print(counts.collect())"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[(10, 1), (8, 3), (6, 1), (2, 2), (4, 1), (20, 1), (12, 1), (18, 1), (22, 1), (5, 3), (9, 2), (1, 1), (17, 1), (3, 1), (7, 2), (23, 1), (19, 1), (15, 1)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0lt31zYihuuJ"},"source":["**sortByKey**() returns a sorted dataset of (K,V) pairs from a dataset of (K,V) pairs. The returned dataset is sorted by keys in ascending or descending order."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWuL6Y-zeGB9","executionInfo":{"status":"ok","timestamp":1619969768840,"user_tz":-330,"elapsed":1606,"user":{"displayName":"Thanveer Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GirciDaF_f0T0PUHFaEhxTlcx__Sco21HoigwgN4w=s64","userId":"16987665677338283692"}},"outputId":"21752b3c-4d84-419e-ca10-ff2bd35eb58d"},"source":["sorts = counts.sortByKey(True)\n","print(sorts.collect())"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[(1, 1), (2, 2), (3, 1), (4, 1), (5, 3), (6, 1), (7, 2), (8, 3), (9, 2), (10, 1), (12, 1), (15, 1), (17, 1), (18, 1), (19, 1), (20, 1), (22, 1), (23, 1)]\n"],"name":"stdout"}]}]}